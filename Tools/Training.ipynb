{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kenem001\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "import pickle\n",
    "\n",
    "from html.parser import HTMLParser\n",
    "import re\n",
    "import itertools\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "import string\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "from googletrans import Translator\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../Data/data_generalised_cleaned_us_3.csv')\n",
    "\n",
    "df = df_original\n",
    "df = df[df['Translated'].notna()]\n",
    "df = df[df['Rep_Class'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data split\n",
    "\n",
    "def data_split(max):\n",
    "    global X, y, x_train, x_test, y_train, y_test, train_max, test_max\n",
    "\n",
    "    X = df.loc[:, 'Translated']\n",
    "    y = df.loc[:, 'Rep_Class']\n",
    "\n",
    "    ts = 0.8\n",
    "\n",
    "    x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, train_size=ts)\n",
    "\n",
    "    train_max = int(max * ts)\n",
    "    test_max = int(max * (1 - ts))\n",
    "\n",
    "    x_train, x_test, y_train, y_test = \\\n",
    "        np.array(x_train[0:train_max]), \\\n",
    "        np.array(x_test[0:test_max]),  \\\n",
    "        np.array(y_train[0:train_max]),  \\\n",
    "        np.array(y_test[0:test_max])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(input_text):\n",
    "    '''\n",
    "    This function cleans the body received from e-mails so that features\n",
    "    to be processed by the Support Vector Machine are extracted from it \n",
    "    more effectively\n",
    "\n",
    "    via https://www.geeksforgeeks.org/python-efficient-text-data-cleaning/\n",
    "    '''\n",
    "\n",
    "    apos_dict = {\"'s\":\" is\",\"n't\":\" not\",\"'m\":\" am\",\"'ll\":\" will\",\n",
    "           \"'d\":\" would\",\"'ve\":\" have\",\"'re\":\" are\"}\n",
    "\n",
    "    warning_message = 'CAUTION: This email originated from OUTSIDE the Government Email Infrastructure. DO NOT CLICK LINKS or OPEN attachments unless you recognise the sender and know the content is safe.'\n",
    "\n",
    "    if warning_message in input_text:\n",
    "        input_text = re.sub(warning_message, '', input_text)\n",
    "\n",
    "    # Convert to unicode\n",
    "    input_text = unidecode(input_text) \n",
    "\n",
    "    # Remove URLs, hashtags\n",
    "    input_text = re.sub(r'https?:\\/\\/.\\S+', '', input_text)\n",
    "    input_text = re.sub(r'#', '', input_text)\n",
    "\n",
    "    # Contraction replacement\n",
    "    for key, value in apos_dict.items():\n",
    "        if key in input_text:\n",
    "            input_text = input_text.replace(key,value)\n",
    "\n",
    "    # Split attached words\n",
    "    input_text = ' '.join([s for s in re.split('([A-Z][a-z]+[^A-Z]*)', input_text) if s])\n",
    "\n",
    "    # Remove punctuation\n",
    "    input_text_list = []\n",
    "    for word in input_text:\n",
    "        if word not in string.punctuation:\n",
    "            input_text_list.append(word)\n",
    "\n",
    "    input_text_list = ''.join(input_text_list).split(' ')\n",
    "    input_text = ' '.join(input_text_list)\n",
    "\n",
    "    # Translation + Spell check\n",
    "    input_text = re.sub(r'(?<![\\w\\d])kons(?![\\w\\d])', 'konsumatur', input_text)\n",
    "    input_text = re.sub(r'(?<![\\w\\d])cons(?![\\w\\d])', 'consumer', input_text)\n",
    "\n",
    "    # translator = Translator()\n",
    "\n",
    "    # lang = translator.detect(input_text).lang\n",
    "\n",
    "    # input_text = translator.translate(input_text, dest='en').text\n",
    "    # input_text_list = input_text.split(' ')\n",
    "\n",
    "    spell = Speller(lang='en')\n",
    "    \n",
    "    for i in range(len(input_text_list)):\n",
    "        input_text_list[i] = spell(input_text_list[i])\n",
    "\n",
    "    input_text = ' '.join(input_text_list)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    input_text = input_text.lower()\n",
    "\n",
    "    # Remove stopwords\n",
    "    exceptions = ['not']\n",
    "    ignore = ['hi', 'hello', 'dear', 'sir', 'madam', 'ms', 'mr', 'regards']\n",
    "\n",
    "    input_text_tokens = input_text.split()\n",
    "\n",
    "    input_text_list = []\n",
    "    for word in input_text_tokens:\n",
    "        if (word not in stopwords_eng) and (word not in ignore) or (word in exceptions):\n",
    "            input_text_list.append(word)\n",
    "\n",
    "    input_text = ' '.join(input_text_list)\n",
    "\n",
    "    input_text = re.sub(' +', ' ', input_text)\n",
    "\n",
    "    return input_text, lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5809304113802384\n",
      "0.5859284890426759\n",
      "0.5990003844675125\n",
      "0.5993848519800077\n",
      "0.6032295271049596\n",
      "0.6055363321799307\n",
      "0.6151480199923106\n",
      "0.615916955017301\n",
      "0.6163014225297963\n"
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "while True:\n",
    "    data_split(df.shape[0])\n",
    "    features = vec.fit_transform(x_train)\n",
    "    model = svm.SVC(kernel='linear', C=1, gamma=0.01, probability=True)\n",
    "    test = vec.transform(x_test)\n",
    "\n",
    "    model.fit(features, y_train)\n",
    "\n",
    "    score = model.score(test, y_test)\n",
    "\n",
    "    if score > best:\n",
    "        best = score\n",
    "        with open(\"model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        with open(\"vec.pkl\", \"wb\") as f:\n",
    "            pickle.dump(vec, f)\n",
    "\n",
    "        print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6036139946174548\n",
      "0.6143790849673203\n",
      "0.6147635524798154\n",
      "0.6166858900422915\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Programming\\mccaa\\E-Mail-Classification\\Tools\\Training.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programming/mccaa/E-Mail-Classification/Tools/Training.ipynb#ch0000010?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m GridSearchCV(svm\u001b[39m.\u001b[39mSVC(probability\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), tuned_parameters)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programming/mccaa/E-Mail-Classification/Tools/Training.ipynb#ch0000010?line=15'>16</a>\u001b[0m test \u001b[39m=\u001b[39m vec\u001b[39m.\u001b[39mtransform(x_test)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Programming/mccaa/E-Mail-Classification/Tools/Training.ipynb#ch0000010?line=17'>18</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(features, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programming/mccaa/E-Mail-Classification/Tools/Training.ipynb#ch0000010?line=19'>20</a>\u001b[0m score \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mscore(test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Programming/mccaa/E-Mail-Classification/Tools/Training.ipynb#ch0000010?line=21'>22</a>\u001b[0m \u001b[39mif\u001b[39;00m score \u001b[39m>\u001b[39m best:\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\model_selection\\_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    869\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    871\u001b[0m     )\n\u001b[0;32m    873\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 875\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    877\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    878\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    879\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1374\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1375\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\model_selection\\_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    815\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    816\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    817\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    819\u001b[0m         )\n\u001b[0;32m    820\u001b[0m     )\n\u001b[1;32m--> 822\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    823\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    824\u001b[0m         clone(base_estimator),\n\u001b[0;32m    825\u001b[0m         X,\n\u001b[0;32m    826\u001b[0m         y,\n\u001b[0;32m    827\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    828\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    829\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    830\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    831\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    832\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    833\u001b[0m     )\n\u001b[0;32m    834\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    835\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    836\u001b[0m     )\n\u001b[0;32m    837\u001b[0m )\n\u001b[0;32m    839\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    840\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    841\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:708\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    705\u001b[0m result[\u001b[39m\"\u001b[39m\u001b[39mfit_error\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    707\u001b[0m fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n\u001b[1;32m--> 708\u001b[0m test_scores \u001b[39m=\u001b[39m _score(estimator, X_test, y_test, scorer, error_score)\n\u001b[0;32m    709\u001b[0m score_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time \u001b[39m-\u001b[39m fit_time\n\u001b[0;32m    710\u001b[0m \u001b[39mif\u001b[39;00m return_train_score:\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:767\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, error_score)\u001b[0m\n\u001b[0;32m    765\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test)\n\u001b[0;32m    766\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 767\u001b[0m         scores \u001b[39m=\u001b[39m scorer(estimator, X_test, y_test)\n\u001b[0;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m error_score \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:429\u001b[0m, in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_passthrough_scorer\u001b[39m(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    428\u001b[0m     \u001b[39m\"\"\"Function that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[1;32m--> 429\u001b[0m     \u001b[39mreturn\u001b[39;00m estimator\u001b[39m.\u001b[39mscore(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\base.py:666\u001b[0m, in \u001b[0;36mClassifierMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[39mReturn the mean accuracy on the given test data and labels.\u001b[39;00m\n\u001b[0;32m    643\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    662\u001b[0m \u001b[39m    Mean accuracy of ``self.predict(X)`` wrt. `y`.\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    664\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy_score\n\u001b[1;32m--> 666\u001b[0m \u001b[39mreturn\u001b[39;00m accuracy_score(y, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X), sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\svm\\_base.py:810\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    808\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    809\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    811\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\svm\\_base.py:435\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    433\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    434\u001b[0m predict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_predict \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dense_predict\n\u001b[1;32m--> 435\u001b[0m \u001b[39mreturn\u001b[39;00m predict(X)\n",
      "File \u001b[1;32mc:\\Users\\kenem001\\Miniconda3\\envs\\email\\lib\\site-packages\\sklearn\\svm\\_base.py:481\u001b[0m, in \u001b[0;36mBaseLibSVM._sparse_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    477\u001b[0m kernel_type \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sparse_kernels\u001b[39m.\u001b[39mindex(kernel)\n\u001b[0;32m    479\u001b[0m C \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m  \u001b[39m# C is not useful here\u001b[39;00m\n\u001b[1;32m--> 481\u001b[0m \u001b[39mreturn\u001b[39;00m libsvm_sparse\u001b[39m.\u001b[39;49mlibsvm_sparse_predict(\n\u001b[0;32m    482\u001b[0m     X\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    483\u001b[0m     X\u001b[39m.\u001b[39;49mindices,\n\u001b[0;32m    484\u001b[0m     X\u001b[39m.\u001b[39;49mindptr,\n\u001b[0;32m    485\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mindices,\n\u001b[0;32m    487\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msupport_vectors_\u001b[39m.\u001b[39;49mindptr,\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dual_coef_\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_intercept_,\n\u001b[0;32m    490\u001b[0m     LIBSVM_IMPL\u001b[39m.\u001b[39;49mindex(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impl),\n\u001b[0;32m    491\u001b[0m     kernel_type,\n\u001b[0;32m    492\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[0;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[0;32m    494\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[0;32m    495\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m    496\u001b[0m     C,\n\u001b[0;32m    497\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight_,\n\u001b[0;32m    498\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[0;32m    499\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[0;32m    500\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[0;32m    501\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[0;32m    502\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_n_support,\n\u001b[0;32m    503\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probA,\n\u001b[0;32m    504\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_probB,\n\u001b[0;32m    505\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best = 0\n",
    "\n",
    "vec = CountVectorizer()\n",
    "\n",
    "while True:\n",
    "    data_split(df.shape[0])\n",
    "    features = vec.fit_transform(x_train)\n",
    "\n",
    "    tuned_parameters = {\n",
    "        'kernel': ['linear'],\n",
    "        'gamma': [0.001, 0.01, 0.1],\n",
    "        'C': [0.1, 1, 10]\n",
    "    }\n",
    "\n",
    "    model = GridSearchCV(svm.SVC(probability=True), tuned_parameters)\n",
    "    test = vec.transform(x_test)\n",
    "\n",
    "    model.fit(features, y_train)\n",
    "\n",
    "    score = model.score(test, y_test)\n",
    "\n",
    "    if score > best:\n",
    "        best = score\n",
    "        with open(\"model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "        with open(\"vec.pkl\", \"wb\") as f:\n",
    "            pickle.dump(vec, f)\n",
    "\n",
    "        print(best)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5276381909547738\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "data_split(1000)\n",
    "features = vec.fit_transform(x_train)\n",
    "model = svm.SVC(kernel='linear', C=1, gamma=0.01, probability=True)\n",
    "test = vec.transform(x_test)\n",
    "\n",
    "model.fit(features, y_train)\n",
    "\n",
    "score = model.score(test, y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Contract and Sales', 'Delivery of Goods/Provision of Service',\n",
       "       'Flights', 'Invoicing/Billing', 'Pricing Tariff',\n",
       "       'Quality of Goods and Service', 'Unfair Commercial Practice',\n",
       "       'Warranty/Statutory Commercial Guarantees'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6036139946174548\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer()\n",
    "data_split(df.shape[0])\n",
    "features = vec.fit_transform(x_train)\n",
    "\n",
    "tuned_parameters = {\n",
    "    'kernel' : ['linear'],\n",
    "    'gamma' : [0.001, 0.01, 0.1],\n",
    "    'C' : [0.1, 1, 10]\n",
    "}\n",
    "model = GridSearchCV(svm.SVC(probability=True), tuned_parameters)\n",
    "test = vec.transform(x_test)\n",
    "\n",
    "model.fit(features, y_train)\n",
    "\n",
    "score = model.score(test, y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44b3ccef905aea8493e9a0c231a38d622c137f2c59b91b8403c0480fbeb074fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
